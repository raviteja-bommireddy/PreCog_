# Language Representations Project

This project explores the science of word embeddings, using both co-occurrence-based methods and neural embeddings (Word2Vec, FastText), as well as cross-lingual alignment techniques for English and Hindi.

## ðŸ”§ Structure

- `notebooks/`: Contains all major steps in separate notebooks
- `data/`: Corpora and evaluation datasets
- `models/`: Saved embedding matrices
- `utils/`: Python scripts for reusable functions
- `results/`: Evaluation outputs (t-SNE plots, metrics)

## ðŸš€ Tasks Covered

- âœ… Dense Word Embeddings from Co-occurrence
- âœ… Dimensionality Reduction (SVD, PCA)
- âœ… Evaluation via Similarity, Clustering, Visualization
- âœ… Comparison with Neural Embeddings
- âœ… Cross-lingual Alignment (EN â†” HI)
- ðŸ”œ Harmful Bias Evaluation (Static & Contextual)

## ðŸ’» How to Run

1. Open notebooks from the `notebooks/` folder in Google Colab
2. Install dependencies from `requirements.txt` if needed
3. Follow the step-by-step cells inside each notebook
